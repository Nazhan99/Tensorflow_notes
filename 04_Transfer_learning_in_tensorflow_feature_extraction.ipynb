{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Transfer_learning_in_tensorflow_feature_extraction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPBioXvZr1YjlUVAbPEVSW9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nazhan99/Tensorflow_notes/blob/main/04_Transfer_learning_in_tensorflow_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transfer learning with tensorflow part 1: Feature Extraction\n",
        "\n",
        "Transfer learning is leveraging a working model's existing architecture and learned pattern for our own data.\n",
        "\n",
        "The two main benefits:\n",
        "1. Can leverage an existing neural network architecture proven to work on problems similar to our own.\n",
        "2. Can leverage a working neural network architecture which has already learned patterns on similar data to our own, then we can adapt those patterns to our own data,"
      ],
      "metadata": {
        "id": "EtzN0jqJssXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Are we using a GPU?\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNkniM1tteQZ",
        "outputId": "745d754e-f00a-4843-b88c-730fc1da65de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb 19 06:17:01 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download and becoming one with the data"
      ],
      "metadata": {
        "id": "bN3d-GivtsxX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get data (10% of 10 food classes from Food101)\n",
        "import zipfile\n",
        "\n",
        "#download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "#unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjDDFVV8t4V6",
        "outputId": "da7f776d-57b8-45a1-ebaa-846768a127fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-19 06:17:01--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 108.177.125.128, 142.250.157.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  50.1MB/s    in 3.2s    \n",
            "\n",
            "2022-02-19 06:17:05 (50.1 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many images in each folder\n",
        "import os\n",
        "\n",
        "#walk through 10 percent data directory and list number of files\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'. \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OvwY0_quXE2",
        "outputId": "75906130-4749-4a16-c16f-5dcb52efe2e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'. \n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'. \n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'. \n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'. \n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating data loaders (preparing the data)\n",
        "\n",
        "we will ise the ImageDataGenerator class to load in our images in batches."
      ],
      "metadata": {
        "id": "fUFziqEIu4Ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#setup data inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224,224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print(\"Training images:\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size=IMAGE_SHAPE,\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          class_mode=\"categorical\")\n",
        "\n",
        "test_data_10_percent = test_datagen.flow_from_directory(test_dir,\n",
        "                                                        target_size= IMAGE_SHAPE,\n",
        "                                                        batch_size=BATCH_SIZE,\n",
        "                                                        class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9izat9uviNT",
        "outputId": "5da4f604-cb01-4072-d734-7a7efa6f8cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks (things to run whilst our model trains)\n",
        "\n",
        "Callbacks are extra functionallity you can add to your models to be performed during or after training. Some of the most popular callbacks:\n",
        " \n",
        " * Tracking experiments with tensorflow callback\n",
        " * Model checkpoint with ModelCheckpoint callback\n",
        " * Stopping a model from training (before it trains too long and overfit with EarlyStopping callbacks"
      ],
      "metadata": {
        "id": "Cqi4W069wj0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create TensorBoard callbacks (functionized because we need to create a new one for each model\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d=%H%M%S\")\n",
        "  tensorboard_callback= tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "  print(f\"Saving TensorBoard log files to : {log_dir}\")\n",
        "  return tensorboard_callback\n"
      ],
      "metadata": {
        "id": "5tO4W_8jyO1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using Tensorflow Hub\n",
        "access pretrained model through https://tfhub.dev/\n",
        "\n",
        "use the following feature vector model link:\n",
        "https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector\n"
      ],
      "metadata": {
        "id": "F1H4lKpTzINP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compare the following two models \n",
        "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n",
        "\n",
        "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector\""
      ],
      "metadata": {
        "id": "ZYy4GHVQ1tv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import dependencies\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "IRcTNTuG1lFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make a create_model() function to create a model from a URL\n",
        "def create_model(model_url, num_classes=10):\n",
        "  \"\"\"\n",
        "  Takes a tensorflow hub URL and creates a keras sequential model with it.\n",
        "\n",
        "  args:\n",
        "  model_url (str): A tensorflow hub feature extraction url.\n",
        "  num_classes (int): numbet of output neurons in the output layer,\n",
        "  should be equal to number of target classes, default 10.\n",
        "\n",
        "  Returns:\n",
        "  An uncompiled keras sequential model with model_url as feature extractor\n",
        "  layer and Dense output layer with num_classes output layers.\n",
        "\n",
        "  \"\"\"\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable =False, #free the already learned patterns\n",
        "                                           name=\"feature_extraction_layer\",\n",
        "                                           input_shape=IMAGE_SHAPE+(3,))\n",
        "\n",
        "  #create our own model\n",
        "  model = tf.keras.Sequential([\n",
        "                               feature_extractor_layer,\n",
        "                               layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")\n",
        "  ]) \n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "AcdoAok43Ylo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and testing ResNet tensorflow model"
      ],
      "metadata": {
        "id": "ZskMco-45ESU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create Resnet model\n",
        "resnet_model = create_model(resnet_url,\n",
        "                            num_classes=train_data_10_percent.num_classes)"
      ],
      "metadata": {
        "id": "GUAxSLhl5BR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3emuPSnx5UJw",
        "outputId": "9d20efd0-9d8c-4af5-eae0-95b1c7fc000f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extraction_layer (K  (None, 2048)             23564800  \n",
            " erasLayer)                                                      \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,585,290\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the resnet model\n",
        "resnet_model.compile(loss =\"categorical_crossentropy\",\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "CUHjCmia5nNj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the resnet model to the data (10 percent of 10 classes)\n",
        "resnet_history= resnet_model.fit(train_data_10_percent,\n",
        "                                 epochs=5,\n",
        "                                 steps_per_epoch=len(train_data_10_percent),\n",
        "                                 validation_data=test_data_10_percent,\n",
        "                                 validation_steps=len(test_data_10_percent),\n",
        "                                 callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "                                                                        experiment_name=\"resnet50V2\")])"
      ],
      "metadata": {
        "id": "VLAlvMs355Nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2ccde0-9600-4a7c-cbb7-bc81be56d603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to : tensorflow_hub/resnet50V2/20220219=062104\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 23s 971ms/step - loss: 1.2382 - accuracy: 0.6293 - val_loss: 0.9968 - val_accuracy: 0.6844\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 21s 908ms/step - loss: 0.7420 - accuracy: 0.7840 - val_loss: 0.7942 - val_accuracy: 0.7452\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 21s 902ms/step - loss: 0.5352 - accuracy: 0.8493 - val_loss: 0.7383 - val_accuracy: 0.7608\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 21s 897ms/step - loss: 0.4181 - accuracy: 0.8947 - val_loss: 0.6932 - val_accuracy: 0.7764\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 21s 896ms/step - loss: 0.3411 - accuracy: 0.9320 - val_loss: 0.6906 - val_accuracy: 0.7752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NQAe1M0ioRH9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}