{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_SkimLit_NLP_milestone_project_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1dGXMEDPSyU/uXQxpkXz8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nazhan99/Tensorflow_notes/blob/main/09_SkimLit_NLP_milestone_project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Milestone project 2: SkimLit\n",
        "\n",
        "The purpose of this notebook is to build an NLP model to make reading material abstracts easier.\n",
        "\n",
        "The paper we are replicating (the source of the dataset that we will be using is available here: https://arxiv.org/abs/1710.06071\n",
        "\n",
        "And reading through the paper above, we see that the model architecture that they use to achieve their best resutls is available here: https://arxiv.org/abs/1612.05251\n"
      ],
      "metadata": {
        "id": "rsToIgNnjm6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confirm acces to GPU\n"
      ],
      "metadata": {
        "id": "SfQAd2ZvIH8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1dZvqThIbkM",
        "outputId": "5bf0c612-1a4c-4f1f-e0cd-c827dc12254e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 27 04:49:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data\n",
        "\n",
        "Since we will be replicating the paper above (PubMed 200 RCT), let's download the dataset they used.\n",
        "\n",
        "We can do so from the author Github: https://github.com/Franck-Dernoncourt/pubmed-rct"
      ],
      "metadata": {
        "id": "LXQtE9R6Iii8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqSgeAnDJSs0",
        "outputId": "361932e6-8015-424d-c8a6-117ba05e89d8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check what files are in the PubMed_20K dataset\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Rp1we2dJmZu",
        "outputId": "57c0a0fb-56a3-4ba7-b3a6-0bb634d6fd1b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start our experiments using the 20k dataset with numbers replaced by \"@\" sign\n",
        "data_dir = \"/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "MbeqWOxAKVh0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check all of the filenames in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz_9vb-xLfH7",
        "outputId": "d05c7c30-3966-4950-d5d8-b1466a1c6bce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess data\n",
        "\n",
        "Now we have got some text data, it is time to understand the data.\n",
        "\n",
        "The best way to understand it is to visualize the data."
      ],
      "metadata": {
        "id": "x6TfvN_ALtOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create funciton to read the lines of a document \n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Read filename (a text filename) and returns the lines oof text as a list.\n",
        "\n",
        "  Args:\n",
        "  filename: a string containing the target filepath.\n",
        "\n",
        "  Return:\n",
        "  A list of string with one string per line from the target filename.\n",
        "  \"\"\"\n",
        "\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "6ZA8yAp9Kr1b"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's read in the training lines\n",
        "train_lines = get_lines(data_dir + \"train.txt\") #read teh lines with the training file\n",
        "train_lines[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlqqKB50Lbyu",
        "outputId": "27eeca13-b9da-44dd-9ccd-7de6cd6c2e96"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MB7Ou2oLqV_",
        "outputId": "ba51c206-a906-4f52-a477-0849b58240d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's thing about how we want our data to look\n",
        "\n",
        "How I think our data would be best represented...\n",
        "\n",
        "`[{'line_number': 0,\n",
        "   'target': 'BACKGROUND',\n",
        "   'text': \"text\".\\n\n",
        "   'total_lines': 11 },\n",
        "   ...]`"
      ],
      "metadata": {
        "id": "l87Zsyv2MM9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"\n",
        "  Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in filename, reads it contents and sorts through each line,\n",
        "  extracting things like the target label, the text of the sentence,\n",
        "  how many sentences are in the current abstract and what sentence\n",
        "  number the target line is.\n",
        "  \"\"\"\n",
        "\n",
        "  input_lines = get_lines(filename) #get all lines from filename\n",
        "  abstract_line= \"\" #create an empty abstract\n",
        "  abstract_samples = [] #create an empty list of abstracts\n",
        "\n",
        "  #loop through each line in the target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): #check to see if the is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" #reset the abstract string if the line is an ID line\n",
        "\n",
        "    elif line.isspace(): #check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines()\n",
        "\n",
        "      #iterate through each line in a single abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {}#create an empty dictionary for each line\n",
        "        target_text_split = abstract_line.split(\"\\t\") #split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] #get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() #get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number #what number line does the line appear \n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 #how many total lines are there in the target abstract?\n",
        "      abstract_samples.append(line_data) #add line data to abstract samples list\n",
        "\n",
        "    else: #if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "\n",
        "  return abstract_samples\n"
      ],
      "metadata": {
        "id": "9qdkjnRbNatf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get data from file and process it\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") #dev is another name for validation dataset\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "print(len(train_samples), len(val_samples), len(test_samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onTTxvIP84uP",
        "outputId": "be8506c6-48ac-4028-97c3-96da62a1deb6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15000 2500 2500\n",
            "CPU times: user 435 ms, sys: 59.8 ms, total: 495 ms\n",
            "Wall time: 500 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the first abstract of our training data\n",
        "train_samples[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jJ0MNKj9yUN",
        "outputId": "7a946d3b-7673-4d85-d61b-2f79a236d7dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 11,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 10,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'results further suggest that attention maintenance on food relates to eating motivation when in a neutral affective state , and might therefore be a cognitive mechanism contributing to increased food intake in general , but maybe not during sad mood .',\n",
              "  'total_lines': 10},\n",
              " {'line_number': 14,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'http://www.clinicaltrials.gov number nct@ .',\n",
              "  'total_lines': 14},\n",
              " {'line_number': 16,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'data management and statistical analyses were conducted independently by vertical ( paris , france ) .',\n",
              "  'total_lines': 16},\n",
              " {'line_number': 11,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'the findings suggest that recall with em causes @-hchanges in memory vividness/emotionality , which may explain part of the emdr treatment effect , and these effects are related to intervention duration .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 12,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'how the intervention can be brought to scale ( in particular , how to train physicians to use mi effectively and how best to train rds and integrate them into primary care settings ) also merits future research .',\n",
              "  'total_lines': 12},\n",
              " {'line_number': 9,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'antithrombin administration in patients with low at activity after surgery with cardiopulmonary bypass reduces postoperative thrombin generation and fibrinolysis with no effects on platelet activation and inflammatory response .',\n",
              "  'total_lines': 9},\n",
              " {'line_number': 10,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'non-transferred patients presenting to primary sites had the lowest event rates and the best long-term survival .',\n",
              "  'total_lines': 10},\n",
              " {'line_number': 8,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'we found no benefit in survival or severity of circulatory shock with targeted temperature management at @ c as compared to @ c in patients with shock on admission after ohca .',\n",
              "  'total_lines': 8},\n",
              " {'line_number': 7,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'this pattern of increased activations in fh + youths may be at least partially due to impaired forebrain white matter development leading to greater activations/less efficient neural communication during task performance .',\n",
              "  'total_lines': 7}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our data is the format of a list of dictionaries, how about we run it into a DataFrame to further visualize our data"
      ],
      "metadata": {
        "id": "KC-_GfKsNy3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "\n",
        "train_df.head(10)"
      ],
      "metadata": {
        "id": "-I05lnaO-Nr2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "e431c3cb-2050-462a-d6fc-c3b2666cfc8b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        target                                               text  \\\n",
              "0  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
              "1  CONCLUSIONS  results further suggest that attention mainten...   \n",
              "2   BACKGROUND        http://www.clinicaltrials.gov number nct@ .   \n",
              "3   BACKGROUND  data management and statistical analyses were ...   \n",
              "4  CONCLUSIONS  the findings suggest that recall with em cause...   \n",
              "5  CONCLUSIONS  how the intervention can be brought to scale (...   \n",
              "6  CONCLUSIONS  antithrombin administration in patients with l...   \n",
              "7  CONCLUSIONS  non-transferred patients presenting to primary...   \n",
              "8  CONCLUSIONS  we found no benefit in survival or severity of...   \n",
              "9  CONCLUSIONS  this pattern of increased activations in fh + ...   \n",
              "\n",
              "   line_number  total_lines  \n",
              "0           11           11  \n",
              "1           10           10  \n",
              "2           14           14  \n",
              "3           16           16  \n",
              "4           11           11  \n",
              "5           12           12  \n",
              "6            9            9  \n",
              "7           10           10  \n",
              "8            8            8  \n",
              "9            7            7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38a9e443-3f68-4cf1-b607-fed38207b420\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>results further suggest that attention mainten...</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>http://www.clinicaltrials.gov number nct@ .</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>data management and statistical analyses were ...</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>the findings suggest that recall with em cause...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>how the intervention can be brought to scale (...</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>antithrombin administration in patients with l...</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>non-transferred patients presenting to primary...</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>we found no benefit in survival or severity of...</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>this pattern of increased activations in fh + ...</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38a9e443-3f68-4cf1-b607-fed38207b420')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38a9e443-3f68-4cf1-b607-fed38207b420 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38a9e443-3f68-4cf1-b607-fed38207b420');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of labels in training data\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrfNHbiNOOhz",
        "outputId": "7219b529-b867-40f2-a564-6d93c25a78ab"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CONCLUSIONS    11973\n",
              "BACKGROUND      2692\n",
              "METHODS          228\n",
              "RESULTS          106\n",
              "OBJECTIVE          1\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check the length of different lines\n",
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ykrqFGrZOeI-",
        "outputId": "3eb05833-2a6d-4dca-8bcd-0085254ac713"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Get list of sentences"
      ],
      "metadata": {
        "id": "UsM-dAJ6OqQd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert abstract text lines into lists\n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences= test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ55zhBCO1ai",
        "outputId": "45c4fe29-3b53-41ba-f76e-eb810a17995b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15000, 2500, 2500)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#view the 19 lines of training sentences\n",
        "train_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVX_4HY7PMla",
        "outputId": "838ae3ee-cdad-4ed6-ea37-ce463c0ed4b3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              " 'results further suggest that attention maintenance on food relates to eating motivation when in a neutral affective state , and might therefore be a cognitive mechanism contributing to increased food intake in general , but maybe not during sad mood .',\n",
              " 'http://www.clinicaltrials.gov number nct@ .',\n",
              " 'data management and statistical analyses were conducted independently by vertical ( paris , france ) .',\n",
              " 'the findings suggest that recall with em causes @-hchanges in memory vividness/emotionality , which may explain part of the emdr treatment effect , and these effects are related to intervention duration .',\n",
              " 'how the intervention can be brought to scale ( in particular , how to train physicians to use mi effectively and how best to train rds and integrate them into primary care settings ) also merits future research .',\n",
              " 'antithrombin administration in patients with low at activity after surgery with cardiopulmonary bypass reduces postoperative thrombin generation and fibrinolysis with no effects on platelet activation and inflammatory response .',\n",
              " 'non-transferred patients presenting to primary sites had the lowest event rates and the best long-term survival .',\n",
              " 'we found no benefit in survival or severity of circulatory shock with targeted temperature management at @ c as compared to @ c in patients with shock on admission after ohca .',\n",
              " 'this pattern of increased activations in fh + youths may be at least partially due to impaired forebrain white matter development leading to greater activations/less efficient neural communication during task performance .']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Make numeric labels (ML models require numeric labels)"
      ],
      "metadata": {
        "id": "qJ-oSEMXPRqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse = False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1,1,))\n",
        "\n",
        "\n",
        "#check what one hot encoded labels look like\n",
        "train_labels_one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8SfzE_-C-HJ",
        "outputId": "66dd0ae3-aeea-4d50-d212-781a10c869e1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.constant(train_labels_one_hot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCgPNI8ND2wl",
        "outputId": "36882c4c-eed9-46e9-9559-894c0fc5d370"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(15000, 5), dtype=float64, numpy=\n",
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYZnMHYBDSKL",
        "outputId": "2ab26283-3a25-4d08-b754-64618c1ed843"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label encode labels"
      ],
      "metadata": {
        "id": "0UViNo1TDcC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract labels (\"target\" columns) and encode them into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.fit_transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.fit_transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTo1hUIyEmgW",
        "outputId": "a4b479a3-ce65-41db-a70e-7a2223aae659"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names and number of classes from LabelEncoder instance\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Jr6ZCzAFvyo",
        "outputId": "d9eb974c-1f02-45ea-a9af-c9730726c6e9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'RESULTS'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Starting a series of modelling experiments...\n",
        "\n",
        "As usual, we are going to be trying a bunch of different models and seeing which one works best. \n",
        "And as alaways, we are going to start with a baseline (TF-IDF Multinomial Naive Bayes classifier)."
      ],
      "metadata": {
        "id": "AQg94ddhG8Sw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0: Getting a baseline"
      ],
      "metadata": {
        "id": "jvO5CaeZGRLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer #turn text to number\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#create a pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tf-idf\", TfidfVectorizer()),\n",
        "                    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "#Fit the pipeline into the training data\n",
        "model_0.fit(X = train_sentences,\n",
        "            y = train_labels_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucyHElkhHVpQ",
        "outputId": "a572f4d8-f7b8-47c7-f5e9-d1b8c8f1b640"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate baseline model on validation dataset\n",
        "model_0.score(X = val_sentences,\n",
        "                 y = val_labels_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzNS6hRsIHIr",
        "outputId": "0041ba8d-3f3b-4157-ea60-3000c7262fa7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9328"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions using our baseline model\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUtiUxAOIT3K",
        "outputId": "9b423dc8-6f03-40ba-fa59-6cbfbcfa99d8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akQTUEy4Ih6S",
        "outputId": "f046be07-79d1-40a7-a609-fbb1d1308283"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download helper_function script\n"
      ],
      "metadata": {
        "id": "mO9Z66EBIkNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uttp0XSIqPH",
        "outputId": "df2b8041-7a88-4b2a-c323-b6b225a7aa87"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-27 04:49:46--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: helper_functions.py\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-03-27 04:49:47 (59.3 MB/s) - helper_functions.py saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import calculate_results"
      ],
      "metadata": {
        "id": "ZSckiUnqI9mX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate baseline results\n",
        "baseline_results = calculate_results(y_true = val_labels_encoded,\n",
        "                                     y_pred = baseline_preds)\n",
        "\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD4nHMzSJBrk",
        "outputId": "a177ac9b-0910-47dd-ca07-3e6cf1742ed1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 93.28,\n",
              " 'f1': 0.9221296639297097,\n",
              " 'precision': 0.9118391760786424,\n",
              " 'recall': 0.9328}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing our data (the text) for deep sequence models\n",
        "\n",
        "Before we start building deeper models, we have got to create vectorization and embedding layers."
      ],
      "metadata": {
        "id": "kP9nVtnSJPvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "7Rasr-eyKPSv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#how long is each sentence on average?\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqK2IO4DKW4i",
        "outputId": "dceca3ee-53bf-40fa-85d9-9ec595dd6ba3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.316933333333335"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#what is the distribution look like?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=20);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Y7yMc9xOKxbO",
        "outputId": "05d079bb-9170-41d8-d2d8-b044beeea555"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how long of a sentence length covers 95% of examples?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqK2r9X0LE9T",
        "outputId": "75a39d11-d2e9-4abf-c927-f8a050995ccf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum sequence length in the training set\n",
        "max(sent_lens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJSVo-v5LUAO",
        "outputId": "e12a23d2-d1ea-407c-f783-51cd1fc5ebec"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "215"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create text vectorizer layer\n",
        "\n",
        "we want to make a layer which maps our text from words to numbers"
      ],
      "metadata": {
        "id": "D1JVegrrLg1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#how many words are in vocab? (taken from table 2 in: https://arxiv.org/abs/1612.05251)\n",
        "max_tokens = 68000"
      ],
      "metadata": {
        "id": "UAiPfazkMAqg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create text vectorizer\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens, #number of word in vocab\n",
        "                                    output_sequence_length = output_seq_len) #desired output length of vectorized sequences"
      ],
      "metadata": {
        "id": "ZfrolrzANNbx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "wmGXAooZNuzS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test out text vectorizer on random sentences\n",
        "import random\n",
        "target_sentences = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentences}\")\n",
        "print(f\"\\nLength of the text: {len(target_sentences)}\")\n",
        "print(f\"\\vVectorized text:{text_vectorizer([target_sentences])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf3lWpK_OHm-",
        "outputId": "21452e7a-dcad-4027-aeb8-87e97b528b5e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "esomeprazole at a maintenance dose of @mg once daily offers effective long-term treatment for chronic gerd in patients initially responsive to the medication , with durable symptom control and sustained reductions in intraesophageal acid exposure .\n",
            "\n",
            "Length of the text: 248\n",
            "\u000bVectorized text:[[ 3597    27     8   477   121     3   178   772   236   855    32   130\n",
            "     19     9   235  3994     5    11  3540  3443     6     2   441     7\n",
            "   1797   618    94     4   463   490     5 15991   520   352     0     0\n",
            "      0     0     0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many words in our training vocabulary\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocab: {len(rct_20k_text_vocab)}\")\n",
        "print(f\"Most common words in the vocab: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least common words in the vocab: {rct_20k_text_vocab[-5:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEJtlw6hOrIy",
        "outputId": "a1a50a14-1a03-4dbb-f8e2-efa76788873b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 20772\n",
            "Most common words in the vocab: ['', '[UNK]', 'the', 'of', 'and']\n",
            "Least common words in the vocab: ['aads', 'aadrenoceptor', 'aad', 'aaca', 'aaaaiawc']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the config of our text vectorizer \n",
        "text_vectorizer.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSAoLD73PsTR",
        "outputId": "4d668db3-9e69-4f34-d860-b27dd7a12999"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_input_shape': (None,),\n",
              " 'dtype': 'string',\n",
              " 'idf_weights': None,\n",
              " 'max_tokens': 68000,\n",
              " 'name': 'text_vectorization',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 40,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'ragged': False,\n",
              " 'sparse': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True,\n",
              " 'vocabulary': None}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create custom text embedding\n"
      ],
      "metadata": {
        "id": "DxI1vYd0QCrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create token embedding layer\n",
        "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab),\n",
        "                               output_dim = 128, # Note: different embedding sizes result in drastically different number of paratemeters to train\n",
        "                               mask_zero = True, #use masking to handle variable sequence lengths (Save space)\n",
        "                               name =\"token_embedding\")"
      ],
      "metadata": {
        "id": "0LdHZyiNO6bU"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show example embedding \n",
        "print(f\"Sentence before vectorization\\n {target_sentences}\\n\")\n",
        "vectorized_sentences = text_vectorizer([target_sentences])\n",
        "print(f\"Sentence after vectorizer (before embedding):\\n {vectorized_sentences}\\n\")\n",
        "embedded_sentences = token_embed(vectorized_sentences)\n",
        "print(f\"Sentence after embedding:\\n {embedded_sentences}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedded_sentences.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm7GEA2KQFJe",
        "outputId": "24160cec-86fa-482e-f6f1-fb3bdfd8ead6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization\n",
            " esomeprazole at a maintenance dose of @mg once daily offers effective long-term treatment for chronic gerd in patients initially responsive to the medication , with durable symptom control and sustained reductions in intraesophageal acid exposure .\n",
            "\n",
            "Sentence after vectorizer (before embedding):\n",
            " [[ 3597    27     8   477   121     3   178   772   236   855    32   130\n",
            "     19     9   235  3994     5    11  3540  3443     6     2   441     7\n",
            "   1797   618    94     4   463   490     5 15991   520   352     0     0\n",
            "      0     0     0     0]]\n",
            "\n",
            "Sentence after embedding:\n",
            " [[[ 0.04429812 -0.03112711 -0.04536326 ... -0.01461469  0.04759726\n",
            "   -0.02422502]\n",
            "  [ 0.01789001  0.01601669 -0.00417365 ...  0.02039416  0.02919401\n",
            "   -0.04315674]\n",
            "  [-0.00453942  0.0220327  -0.02338771 ...  0.04303637 -0.04678658\n",
            "    0.04848938]\n",
            "  ...\n",
            "  [-0.02930906  0.01348497 -0.03629399 ... -0.01716571 -0.04566286\n",
            "   -0.006262  ]\n",
            "  [-0.02930906  0.01348497 -0.03629399 ... -0.01716571 -0.04566286\n",
            "   -0.006262  ]\n",
            "  [-0.02930906  0.01348497 -0.03629399 ... -0.01716571 -0.04566286\n",
            "   -0.006262  ]]]\n",
            "\n",
            "Embedded sentence shape: (1, 40, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating datasets (making sure our data loads as fast as possible) using TensorFlow tf.data API\n",
        "\n",
        "https://www.tensorflow.org/guide/data\n",
        "\n",
        "https://www.tensorflow.org/guide/data_performance"
      ],
      "metadata": {
        "id": "MXdmxUSZQzFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzzVLKnFRnPT",
        "outputId": "163a4249-9e4a-41a3-83f7-b068ed783e74"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Take the TensorSlicesDataset's and turn them into prefetched datasets\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZdtp2s1S0dd",
        "outputId": "974d3e7a-e6a6-42ee-f863-4763582bc389"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1:Conv1D with token embeddings"
      ],
      "metadata": {
        "id": "YTT9UnpHSvwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create 1D conv model to process sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = text_vectorizer(inputs)\n",
        "token_embeddings = token_embed(text_vectors)\n",
        "#expand_layer = tf.keras.layers.Lambda(lambda x: tf.expand_dims(x , axis =1))\n",
        "#x = expand_layer(token_embeddings)\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\") (token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(5, activation = \"softmax\")(x)\n",
        "#outputs = tf.expand_dims(outputs, axis=-1)\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "#compile \n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "XuwgFhEpUnWM"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nYsBNlsVqFz",
        "outputId": "07d8ab67-90ed-4b19-d14c-623962dd6063"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 40)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " token_embedding (Embedding)  (None, 40, 128)          2658816   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 40, 64)            41024     \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 64)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,700,165\n",
            "Trainable params: 2,700,165\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fit the model\n",
        "history_model_1 = model_1.fit(train_dataset,\n",
        "                              steps_per_epoch= int(0.1*len(train_dataset)),\n",
        "                              epochs = 3,\n",
        "                              validation_data = valid_dataset,\n",
        "                              validation_steps = int(0.1*len(valid_dataset))) #only validate on 10% of batches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITUs5M05V-9e",
        "outputId": "cdf3705e-7cb5-4eef-e7db-3349d4a43b5f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "46/46 [==============================] - 11s 16ms/step - loss: 0.9954 - accuracy: 0.7704 - val_loss: 0.6611 - val_accuracy: 0.7902\n",
            "Epoch 2/3\n",
            "46/46 [==============================] - 1s 11ms/step - loss: 0.4431 - accuracy: 0.8410 - val_loss: 0.3881 - val_accuracy: 0.9018\n",
            "Epoch 3/3\n",
            "46/46 [==============================] - 0s 10ms/step - loss: 0.2857 - accuracy: 0.9327 - val_loss: 0.3157 - val_accuracy: 0.9062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on whole validation dataset\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "metadata": {
        "id": "DpXepVD4Xk_J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a62a39-41e9-4106-dedf-e8ccb6edf6af"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 5ms/step - loss: 0.2694 - accuracy: 0.9244\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2694352865219116, 0.9243999719619751]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make prediction (our model predicts prediction probabilities for each class)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs, model_1_pred_probs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TQ5gJF-ce38",
        "outputId": "26af6a88-ae87-40f9-9e3e-f11a7e45fb5c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1.38032165e-05, 9.99354661e-01, 1.56276830e-04, 5.90084965e-05,\n",
              "         4.16196242e-04],\n",
              "        [8.46786643e-05, 9.98276472e-01, 4.82819160e-04, 1.69145162e-04,\n",
              "         9.86725092e-04],\n",
              "        [1.36318931e-03, 9.94705737e-01, 1.67327549e-03, 3.60684615e-04,\n",
              "         1.89717102e-03],\n",
              "        ...,\n",
              "        [1.05482806e-02, 9.79110003e-01, 5.18809026e-03, 9.45639971e-04,\n",
              "         4.20808839e-03],\n",
              "        [1.05685895e-05, 9.99483347e-01, 1.24096216e-04, 4.45828373e-05,\n",
              "         3.37257254e-04],\n",
              "        [5.93936205e-01, 3.50139439e-01, 3.69266644e-02, 5.17456466e-03,\n",
              "         1.38231516e-02]], dtype=float32), (2500, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert pred probs to classes\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
        "model_1_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVXqZkIkcyBE",
        "outputId": "b60b8e0e-0d6b-4b72-d2bc-c494de7e3f23"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2500,), dtype=int64, numpy=array([1, 1, 1, ..., 1, 1, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pefZLlRedBan",
        "outputId": "6b4a1df4-4761-4ea8-e715-aba12e5eeff8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'RESULTS'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_1_preds)\n",
        "\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vgxgKpTdCS9",
        "outputId": "038a93d6-ed7b-4002-d1a5-4cda1e7a1413"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 92.44,\n",
              " 'f1': 0.9150595556252703,\n",
              " 'precision': 0.9071470656840119,\n",
              " 'recall': 0.9244}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: Feature extraction with pretrained token embeddings\n",
        "\n",
        "Now lets use pretrained word embeddings from tensorflow hub, more specifically the universal sentence encoder: https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "\n",
        "The paper originally used GloVe embeddings however, we are going to use pretrained embeddings,"
      ],
      "metadata": {
        "id": "HfqSZS04dQx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")"
      ],
      "metadata": {
        "id": "zxE-S0O7fH3N"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test out the pretrained embedding on a random sentence\n",
        "random_train_sentence = random.choice(train_sentences)\n",
        "print(f\"Random sentence:\\n {random_train_sentence}\\n\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_train_sentence])\n",
        "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:10]}\\n\")\n",
        "print(f\"Length of sentence embedding: {len(use_embedded_sentence[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19kb1OW3fuEJ",
        "outputId": "9bed7388-4e67-4504-fe58-b33094eb63f0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sentence:\n",
            " cd@ cell reconstitution was positively associated with cd@ count at study visit , time on art , satisfaction with care at clinic , haemoglobin concentration and total lymphocyte count and negatively associated with age .\n",
            "\n",
            "Sentence after embedding:\n",
            "[-0.05229548  0.01819707  0.07437024 -0.01560362 -0.02287305 -0.00961948\n",
            " -0.01990574 -0.05684538  0.07584072  0.06015356]\n",
            "\n",
            "Length of sentence embedding: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building and fitting an NLP feature extraction model using pretrained model using embeddings TensoFlow Hub "
      ],
      "metadata": {
        "id": "okeBTZ8UgW5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature extraction model using TF Hub layer\n",
        "inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs) #tokenize text and create embedding of each sequence (512 long vector)\n",
        "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding)\n",
        "\n",
        "outputs= layers.Dense(5, activation=\"softmax\")(x) #create the output layer\n",
        "model_2 = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name=\"model_2_USE_feature_extractor\")\n",
        "\n",
        "#compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "CXwPW0PmhKR-"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEYT3riKiYC-",
        "outputId": "53e42c27-bf59-4478-b57b-85a47341df11"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_USE_feature_extractor\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None,)]                 0         \n",
            "                                                                 \n",
            " universal_sentence_encoder   (None, 512)              256797824 \n",
            " (KerasLayer)                                                    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model_2 to the data\n",
        "history_model_2 = model_2.fit(train_dataset,\n",
        "                              epochs=3,\n",
        "                              steps_per_epoch=int(0.1*len(train_dataset)),\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1*len(valid_dataset))\n",
        "                              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHpaJbxEia1-",
        "outputId": "2eb5d1c8-1588-405b-e3f1-1b1bf61569e4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "46/46 [==============================] - 5s 54ms/step - loss: 0.9362 - accuracy: 0.8777 - val_loss: 0.4333 - val_accuracy: 0.8839\n",
            "Epoch 2/3\n",
            "46/46 [==============================] - 1s 31ms/step - loss: 0.2767 - accuracy: 0.9253 - val_loss: 0.3137 - val_accuracy: 0.9062\n",
            "Epoch 3/3\n",
            "46/46 [==============================] - 1s 26ms/step - loss: 0.2336 - accuracy: 0.9423 - val_loss: 0.2630 - val_accuracy: 0.9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the whole validation dataset\n",
        "model_2.evaluate(valid_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbKgzuJFjBqK",
        "outputId": "4deaa868-739c-41ad-f5ba-a776cce2da00"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 2s 25ms/step - loss: 0.2106 - accuracy: 0.9376\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2106163501739502, 0.9376000165939331]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make prediction with feature extraction model\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcFGxV1mj2ze",
        "outputId": "bf8c6619-fe26-4410-9409-fe218afd5e62"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.5486679e-03, 9.9404645e-01, 1.8133668e-03, 1.3160355e-03,\n",
              "        1.2753836e-03],\n",
              "       [1.3700281e-03, 9.9640745e-01, 9.4028574e-04, 5.5834866e-04,\n",
              "        7.2385836e-04],\n",
              "       [2.0634752e-02, 9.2459071e-01, 2.2781245e-02, 1.4788321e-02,\n",
              "        1.7205007e-02],\n",
              "       ...,\n",
              "       [1.2141856e-03, 9.9576426e-01, 1.1356059e-03, 8.6858228e-04,\n",
              "        1.0173537e-03],\n",
              "       [4.7165556e-03, 9.8111445e-01, 5.4782708e-03, 4.2088330e-03,\n",
              "        4.4818111e-03],\n",
              "       [3.1451944e-01, 6.4811361e-01, 1.3833472e-02, 9.6124103e-03,\n",
              "        1.3921106e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the prediction probabilities to label\n",
        "model_2_preds= tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR6OmTGkkEdY",
        "outputId": "e9506b26-6a06-4512-ae4c-e0cfdb044309"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2500,), dtype=int64, numpy=array([1, 1, 1, ..., 1, 1, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate results from TF hub pretrained mebedding resutls on val set\n",
        "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vr5KCcgkPU0",
        "outputId": "bf2bc945-beee-4473-e2cc-53ec9f5a1a6a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 93.76,\n",
              " 'f1': 0.9313783717097147,\n",
              " 'precision': 0.934398861486905,\n",
              " 'recall': 0.9376}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7gWEGUtki5t",
        "outputId": "2d3c11fe-4b04-4d34-eba7-841de9b122b6"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 93.28,\n",
              " 'f1': 0.9221296639297097,\n",
              " 'precision': 0.9118391760786424,\n",
              " 'recall': 0.9328}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: Conv1D with character embeddings\n",
        "\n",
        "the paper which we are replicating states they used combination of token and character-level-embeddings.\n",
        "Previously, we have token-level embeddings but we will need to do similar steps for characters if we want to use char-level embeddings."
      ],
      "metadata": {
        "id": "ELkxkEW4klWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a character-level tokenizer"
      ],
      "metadata": {
        "id": "XxSBgD0vlea4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "#Text splitting non-character-level sequence into characters\n",
        "split_chars(random_train_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "PUiLPYSnmK6Z",
        "outputId": "cead400b-4b87-437a-cab6-cff348657bcf"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'c d @   c e l l   r e c o n s t i t u t i o n   w a s   p o s i t i v e l y   a s s o c i a t e d   w i t h   c d @   c o u n t   a t   s t u d y   v i s i t   ,   t i m e   o n   a r t   ,   s a t i s f a c t i o n   w i t h   c a r e   a t   c l i n i c   ,   h a e m o g l o b i n   c o n c e n t r a t i o n   a n d   t o t a l   l y m p h o c y t e   c o u n t   a n d   n e g a t i v e l y   a s s o c i a t e d   w i t h   a g e   .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split sequence-level-data splits into character-level splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "train_chars[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52btMngymdEw",
        "outputId": "e10599e2-1326-4fee-f64f-ad7e00d846c0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['l o w - d o s e   o r a l   p r e d n i s o l o n e   h a d   b o t h   a   s h o r t - t e r m   a n d   a   l o n g e r   s u s t a i n e d   e f f e c t   r e s u l t i n g   i n   l e s s   k n e e   p a i n   ,   b e t t e r   p h y s i c a l   f u n c t i o n   ,   a n d   a t t e n u a t i o n   o f   s y s t e m i c   i n f l a m m a t i o n   i n   o l d e r   p a t i e n t s   w i t h   k n e e   o a   (   c l i n i c a l t r i a l s . g o v   i d e n t i f i e r   n c t @   )   .',\n",
              " 'r e s u l t s   f u r t h e r   s u g g e s t   t h a t   a t t e n t i o n   m a i n t e n a n c e   o n   f o o d   r e l a t e s   t o   e a t i n g   m o t i v a t i o n   w h e n   i n   a   n e u t r a l   a f f e c t i v e   s t a t e   ,   a n d   m i g h t   t h e r e f o r e   b e   a   c o g n i t i v e   m e c h a n i s m   c o n t r i b u t i n g   t o   i n c r e a s e d   f o o d   i n t a k e   i n   g e n e r a l   ,   b u t   m a y b e   n o t   d u r i n g   s a d   m o o d   .',\n",
              " 'h t t p : / / w w w . c l i n i c a l t r i a l s . g o v   n u m b e r   n c t @   .',\n",
              " 'd a t a   m a n a g e m e n t   a n d   s t a t i s t i c a l   a n a l y s e s   w e r e   c o n d u c t e d   i n d e p e n d e n t l y   b y   v e r t i c a l   (   p a r i s   ,   f r a n c e   )   .',\n",
              " 't h e   f i n d i n g s   s u g g e s t   t h a t   r e c a l l   w i t h   e m   c a u s e s   @ - h c h a n g e s   i n   m e m o r y   v i v i d n e s s / e m o t i o n a l i t y   ,   w h i c h   m a y   e x p l a i n   p a r t   o f   t h e   e m d r   t r e a t m e n t   e f f e c t   ,   a n d   t h e s e   e f f e c t s   a r e   r e l a t e d   t o   i n t e r v e n t i o n   d u r a t i o n   .']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#what is the average character length?\n",
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBpzG4cvm2w9",
        "outputId": "5203cd06-db52-45e1-9a5a-0b063dc869c1"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "129.99693333333335"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the distribution of our sequences at a character-level\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_lens, bins=7);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "XM-g_kzHneLH",
        "outputId": "1a6078ad-e5a7-42f9-ddff-0ad8c171e7a5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find what character length cover 95% of sequences\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyj3Pe5Rn2Ei",
        "outputId": "21050e2d-07a5-423b-f913-ca94f31140bd"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get all keyboard characters\n",
        "import string \n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vIAGakekoElw",
        "outputId": "20d1bb0b-3745-41db-9421-95f3df21472d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create char-level token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) +2 # add 2 for space and OOV token (OOV = out of vocab. '[UNK] = unknown)\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    #standardize=\"lower_and_strip_punctuation\", \n",
        "                                    name=\"char_vectorizer\")"
      ],
      "metadata": {
        "id": "V9GvxfMgorgG"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adapt character vectorizer to training character\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "id": "oO_PWw3tpZzz"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check character vocab stats\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
        "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
        "print(f\"5 least common characters: {char_vocab[-5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOkglnILpqpU",
        "outputId": "897139d9-d9f2-4d98-f10d-8285b04ad645"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different characters in character vocab: 28\n",
            "5 most common characters: ['', '[UNK]', 'e', 't', 'i']\n",
            "5 least common characters: k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test out character vectorizer\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n {random_train_chars}\")\n",
        "print(f\"Length of random_train_chars: {len(random_train_chars.split())}\")\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\nVectorizerd chars:\\n {vectorized_chars}\")\n",
        "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9IyaSNlqlll",
        "outputId": "5771c0d6-596d-430e-d3e3-dfb627750032"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text:\n",
            " g o + a   e g i s   f s   s h o w e d   t h e   h i g h e s t   r e m i n e r a l i z a t i o n   ;   a n d   ,   a t   t h e   e n d   o f   @   m o n t h s   ,   i t s   c l i n i c a l   s u c c e s s   w a s   h i g h e r   t h a n   o t h e r   f s s   .\n",
            "Length of random_train_chars: 105\n",
            "\n",
            "Vectorizerd chars:\n",
            " [[18  7  5  2 18  4  9 17  9  9 13  7 22  2 12  3 13  2 13  4 18 13  2  9\n",
            "   3  8  2 16  4  6  2  8  5 11  4 26  5  3  4  7  6  5  6 12  5  3  3 13\n",
            "   2  2  6 12  7 17 16  7  6  3 13  9  4  3  9 10 11  4  6  4 10  5 11  9\n",
            "  15 10 10  2  9  9 22  5  9 13  4 18 13  2  8  3 13  5  6  7  3 13  2  8\n",
            "  17  9  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "\n",
            "Length of vectorized chars: 255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a character-level embedding"
      ],
      "metadata": {
        "id": "QgraOyiQryG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create char embedding layer\n",
        "char_embed = layers.Embedding(input_dim=len(char_vocab), #number of different chars\n",
        "                              output_dim=25,\n",
        "                              mask_zero=True,\n",
        "                              name=\"char_embed\")\n",
        "\n"
      ],
      "metadata": {
        "id": "H-JS6uJ8tlhZ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test our character embedding layer\n",
        "print(f\"Charified text:\\n {random_train_chars}\\n\")\n",
        "char_embed_example=char_embed(char_vectorizer([random_train_chars]))\n",
        "print(f\"Embedded chars. (after vectorization and embedding):\\n {char_embed_example}\\n\")\n",
        "print(f\"Character embedding shape: {char_embed_example.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6d3kvOBuQ3F",
        "outputId": "a48475cd-a61f-456b-c3d7-7517081bb733"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text:\n",
            " g o + a   e g i s   f s   s h o w e d   t h e   h i g h e s t   r e m i n e r a l i z a t i o n   ;   a n d   ,   a t   t h e   e n d   o f   @   m o n t h s   ,   i t s   c l i n i c a l   s u c c e s s   w a s   h i g h e r   t h a n   o t h e r   f s s   .\n",
            "\n",
            "Embedded chars. (after vectorization and embedding):\n",
            " [[[ 0.0463573   0.00869886  0.03824463 ...  0.01414535  0.02009713\n",
            "    0.01887289]\n",
            "  [-0.00416329  0.0398172  -0.02579967 ...  0.04358036 -0.00808339\n",
            "    0.00405165]\n",
            "  [ 0.01029478 -0.03345778 -0.01755922 ... -0.00608645 -0.04720128\n",
            "    0.01229503]\n",
            "  ...\n",
            "  [-0.04974635  0.00489453  0.02515448 ... -0.04810535 -0.03000834\n",
            "   -0.02340887]\n",
            "  [-0.04974635  0.00489453  0.02515448 ... -0.04810535 -0.03000834\n",
            "   -0.02340887]\n",
            "  [-0.04974635  0.00489453  0.02515448 ... -0.04810535 -0.03000834\n",
            "   -0.02340887]]]\n",
            "\n",
            "Character embedding shape: (1, 255, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8UK68pc_u0Dy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}